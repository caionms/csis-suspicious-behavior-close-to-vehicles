{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caionms/csis-suspicious-behavior-close-to-vehicles/blob/main/YOLOv8_Suspicious_Behavior_Close_To_Vehicles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT3RRNt-wXns"
      },
      "source": [
        "# **REAL-TIME POSE ESTIMATION WITH YOLOv8**\n",
        "## Author: Caio Nery Matos Santos\n",
        "\n",
        "Code based on: https://github.com/ultralytics/ultralytics\n",
        "\n",
        "### **Sobre o projeto:**\n",
        "\n",
        "O objetivo deste projeto é melhorar a segurança nos estacionamentos universitários, construindo um sistema capaz de reconhecer veículos e indivíduos, avaliando sua proximidade e detectando gestos e ações que são previamente classificados como comportamento suspeitos, e interoperar com sistemas de câmeras a fim de alertar as autoridades competentes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjrLfdBDkMIu"
      },
      "source": [
        "### **Conexão com o Google Drive (Opcional)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRhpqcGFkD2M",
        "outputId": "9c713594-3b53-4750-937b-3d1827989cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount (\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Execute para preparar o ambiente para a detecção**"
      ],
      "metadata": {
        "id": "F1PYfwSaHl-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Instalando o YOLOv8 ...**"
      ],
      "metadata": {
        "id": "IygowPq5Akss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the ultralytics package from PyPI\n",
        "! pip install ultralytics"
      ],
      "metadata": {
        "id": "oEo_hmtiAhtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQSDblCmkTuN"
      },
      "source": [
        "#### **Importando o YOLOv8 e outras bibliotecas ...**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKUpEqtsfX3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2310a549-e900-4b89-a6c4-ac046ac949a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-pose.pt to 'yolov8n-pose.pt'...\n",
            "100%|██████████| 6.51M/6.51M [00:00<00:00, 72.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from os import listdir\n",
        "from os.path import exists, join, basename, splitext, isfile, isdir\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Carrega modelos\n",
        "model = YOLO('yolov8n.pt')\n",
        "model_kpts = YOLO('yolov8n-pose.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Utils**"
      ],
      "metadata": {
        "id": "QahkjqKPa4Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bbox_iou_vehicle(box1, box2):\n",
        "    # Extrai as coordenadas das caixas delimitadoras\n",
        "    x1_box1, y1_box1, x2_box1, y2_box1 = box1\n",
        "    x1_box2, y1_box2, x2_box2, y2_box2 = box2\n",
        "\n",
        "    # Coordenadas da intersecção\n",
        "    x1_intersection = max(x1_box1, x1_box2)\n",
        "    y1_intersection = max(y1_box1, y1_box2)\n",
        "    x2_intersection = min(x2_box1, x2_box2)\n",
        "    y2_intersection = min(y2_box1, y2_box2)\n",
        "\n",
        "    # Área da intersecção\n",
        "    intersection_area = max(0, x2_intersection - x1_intersection + 1) * max(0, y2_intersection - y1_intersection + 1)\n",
        "\n",
        "    # Áreas das caixas delimitadoras\n",
        "    box1_area = (x2_box1 - x1_box1 + 1) * (y2_box1 - y1_box1 + 1)\n",
        "    box2_area = (x2_box2 - x1_box2 + 1) * (y2_box2 - y1_box2 + 1)\n",
        "\n",
        "    # União das áreas\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "    # Cálculo do IoU\n",
        "    iou = intersection_area / union_area\n",
        "\n",
        "    return iou"
      ],
      "metadata": {
        "id": "EpHMafES6YwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_front(kpts):\n",
        "  # Extrai as coordenadas x e y do nariz\n",
        "  x_nariz, y_nariz = kpts[0][0], kpts[0][1]\n",
        "\n",
        "  # Extrai as coordenadas x e y dos olhos\n",
        "  x_olho_esquerdo, y_olho_esquerdo = kpts[1][0], kpts[1][1]\n",
        "  x_olho_direito, y__olho_direito = kpts[2][0], kpts[2][1]\n",
        "\n",
        "  # Ordena as coordenadas\n",
        "  coord_x_olhos = sorted([x_olho_esquerdo, x_olho_direito])\n",
        "\n",
        "  # Extrai as coordenadas x e y dos ouvidos\n",
        "  x_ouvido_esquerdo, y_ouvido_esquerdo = kpts[3][0], kpts[3][1]\n",
        "  x_ouvido_direito, y_ouvido_direito = kpts[4][0], kpts[4][1]\n",
        "\n",
        "  # Ordena as coordenadas\n",
        "  coord_x_ouvidos = sorted([x_ouvido_esquerdo, x_ouvido_direito])\n",
        "\n",
        "  #Se o nariz não estiver entre os olhos ou entre os ouvidos, está de lado\n",
        "  return (coord_x_olhos[0] <= x_nariz <= coord_x_olhos[1]) and (coord_x_ouvidos[0] <= x_nariz <= coord_x_ouvidos[1])"
      ],
      "metadata": {
        "id": "mYkrMpv6H04v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def three_points_angle(kpts, kpts_ind):\n",
        "  # Extrai os pontos para definir o angulo (linha = k_1-k_2 | k_2-k_3)\n",
        "  k_1, k_2, k_3 = kpts_ind[0], kpts_ind[1], kpts_ind[2]\n",
        "\n",
        "  # Ponto 1\n",
        "  x1_coord, y1_coord = kpts[k_1][0], kpts[k_1][1]\n",
        "  # Ponto 2\n",
        "  x2_coord, y2_coord = kpts[k_2][0], kpts[k_2][1]\n",
        "  # Ponto 3\n",
        "  x3_coord, y3_coord = kpts[k_3][0], kpts[k_3][1]\n",
        "\n",
        "  # Calcula os vetores\n",
        "  v1 = (x1_coord - x2_coord, y1_coord - y2_coord)\n",
        "  v2 = (x3_coord - x2_coord, y3_coord - y2_coord)\n",
        "\n",
        "  # Calcula o produto escalar\n",
        "  dot_product = v1[0]*v2[0] + v1[1]*v2[1]\n",
        "\n",
        "  # Calcula as magnitudes dos vetores\n",
        "  v1_mag = math.sqrt(v1[0]**2 + v1[1]**2)\n",
        "  v2_mag = math.sqrt(v2[0]**2 + v2[1]**2)\n",
        "\n",
        "  # Calcula o angulo entre os vetores\n",
        "  # Versão para lidar como erro math domain error\n",
        "  angle = math.acos(min(max(dot_product / (v1_mag * v2_mag), -1), 1))\n",
        "\n",
        "  # Converte o angulo de radianos para graus\n",
        "  angle_degrees = math.degrees(angle)\n",
        "\n",
        "  return angle_degrees"
      ],
      "metadata": {
        "id": "6io68tKQH68P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_squat(kpts):\n",
        "  # Indices dos pontos-chave dos joelhos\n",
        "  kpts_ind_joelho_dir_int = [12, 14, 16]\n",
        "  kpts_ind_joelho_esq_int = [11, 13, 15]\n",
        "\n",
        "  # Calcula os angulos internos dos joelhos\n",
        "  angle_joelho_dir_int = three_points_angle(kpts, kpts_ind_joelho_dir_int)\n",
        "  angle_joelho_esq_int = three_points_angle(kpts, kpts_ind_joelho_esq_int)\n",
        "\n",
        "  # Calcula os angulos externos dos joelhos\n",
        "  angle_joelho_dir_ext = 180 - angle_joelho_dir_int\n",
        "  angle_joelho_esq_ext = 180 - angle_joelho_esq_int\n",
        "\n",
        "  # Calcula a media dos angulos dos joelhos\n",
        "  avg_leg_angle_ext = ((angle_joelho_esq_ext) + (angle_joelho_dir_ext)) // 2\n",
        "  avg_leg_angle_int = ((angle_joelho_esq_int) + (angle_joelho_dir_int)) // 2\n",
        "\n",
        "  # Condicao para definir agachamento (frontal e lateral)\n",
        "  return (is_front(kpts) and angle_joelho_dir_int < 145 and angle_joelho_esq_int < 145 and avg_leg_angle_int < 130)\n",
        "   or (angle_joelho_dir_ext > 60 and angle_joelho_esq_ext > 60 and avg_leg_angle_ext > 80)"
      ],
      "metadata": {
        "id": "bYI-HN-CHvW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_detections(frame, persons, color=None, label=None, line_thickness=3):\n",
        "  # Percorre todas as caixas de pessoas\n",
        "  for person_box in persons:\n",
        "    # Define espessura da linha\n",
        "    tl = line_thickness or round(0.002 * (frame.shape[0] + frame.shape[1]) / 2) + 1\n",
        "\n",
        "    # Define cores para as caixas\n",
        "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
        "\n",
        "    # Extrai coordenadas da caixa\n",
        "    c1, c2 = (int(person_box[0]), int(person_box[1])), (int(person_box[2]), int(person_box[3]))\n",
        "\n",
        "    # Plota a caixa delimitadora\n",
        "    cv2.rectangle(frame, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
        "\n",
        "    # Se existir um label, plota ele\n",
        "    if label:\n",
        "      # Define espessura da fonte\n",
        "      tf = max(tl - 1, 1)\n",
        "\n",
        "      # Extrai o tamanho do texto\n",
        "      t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "\n",
        "      # Define nova coordenada para o retangulo do texto\n",
        "      c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
        "\n",
        "      # Plota o retangulo do texto\n",
        "      cv2.rectangle(frame, c1, c2, color, -1, cv2.LINE_AA)\n",
        "\n",
        "      # Plota o texto definido\n",
        "      cv2.putText(frame, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n"
      ],
      "metadata": {
        "id": "hMndmp9GSymV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_skeleton_kpts(frame, kpts, kpts_conf, color=None, orig_shape=None):\n",
        "    # Define cores para pontos-chave\n",
        "    palette = np.array([[255, 128, 0], [255, 153, 51], [255, 178, 102],\n",
        "                        [230, 230, 0], [255, 153, 255], [153, 204, 255],\n",
        "                        [255, 102, 255], [255, 51, 255], [102, 178, 255],\n",
        "                        [51, 153, 255], [255, 153, 153], [255, 102, 102],\n",
        "                        [255, 51, 51], [153, 255, 153], [102, 255, 102],\n",
        "                        [51, 255, 51], [0, 255, 0], [0, 0, 255], [255, 0, 0],\n",
        "                        [255, 255, 255]])\n",
        "\n",
        "    # Conexoes entre pontos-chave\n",
        "    skeleton = [\n",
        "                #Rosto\n",
        "                [1, 2], [1, 3], [2, 3], [2, 4], [3, 5], [4, 6], [5, 7],\n",
        "                #Braços\n",
        "                [6, 7], [6, 8], [7, 9],  [8, 10], [9, 11],\n",
        "                #Tronco\n",
        "                [7, 13], [6, 12], [12, 13],\n",
        "                #Cintura e pernas\n",
        "                [14, 12], [15, 13], [16, 14], [17, 15]\n",
        "      ]\n",
        "\n",
        "    # Cores base para as linhas (seguindo a ordem de skeleton)\n",
        "    pose_limb_color = palette[[16, 16, 16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 7, 7, 7, 9, 9, 9, 9]]\n",
        "\n",
        "    # Cores base para keypoints (seguindo a ordem definida)\n",
        "    pose_kpt_color = palette[[16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9]]\n",
        "\n",
        "    # Define raio\n",
        "    radius = 5\n",
        "\n",
        "    # Recebe cores caso tenham sido passadas\n",
        "    r, g, b = None\n",
        "    if color is not None:\n",
        "      r, g, b = color[0], color[1], color[2]\n",
        "\n",
        "    # Percorre cada ponto-chave\n",
        "    for kid in range(len(kpts)):\n",
        "      # Extrai as coordenadas desse ponto-chave\n",
        "      x_coord, y_coord = kpts[kid]\n",
        "\n",
        "      # Verifica se as coordenadas estão no limite proporcional e sua confiança\n",
        "      if x_coord % 640 != 0 and y_coord % 640 != 0 and kpts_conf[kid] >= 0.1:\n",
        "        # Plota o circulo desse ponto chave\n",
        "        cv2.circle(frame, (int(x_coord), int(y_coord)), radius, (int(r), int(g), int(b)), -1)\n",
        "\n",
        "    # Percorre cada conexao do esqueleto\n",
        "    for sk_id, sk in enumerate(skeleton):\n",
        "      # Extrai as coordenadas e confiança do primeiro ponto\n",
        "      x,y = kpts[sk[0]-1]\n",
        "      conf1 = kpts_conf[sk[0]-1]\n",
        "      pos1 = (int(x), int(y))\n",
        "\n",
        "      # Extrai as coordenadas e confiança do segundo ponto\n",
        "      x,y = kpts[sk[1]-1]\n",
        "      conf2 = kpts_conf[sk[1]-1]\n",
        "      pos2 =(int(x), int(y))\n",
        "\n",
        "      # Verifica se as coordenadas estão no limite proporcional e sua confiança\n",
        "      if (conf1 >= 0.1 and conf2 >= 0.1 and\n",
        "          0 < pos1[0] % 640 < 640 and 0 < pos1[1] % 640 < 640 and\n",
        "          0 < pos2[0] % 640 < 640 and 0 < pos2[1] % 640 < 640):\n",
        "        # Plota a linha dessa conexao\n",
        "        cv2.line(frame, pos1, pos2, (int(r), int(g), int(b)), thickness=2)"
      ],
      "metadata": {
        "id": "0YIOvOt-_gW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_keypoints_detection(frame, kpts, kpts_conf, box, estado, id, frames_passados, orig_shape=None):\n",
        "  # Cria um texto para plot com o id da pessoa\n",
        "  label = str(id)\n",
        "\n",
        "  # Adiciona no texto o estado em que a pessoa se encontra e define a cor correspondente\n",
        "  if(estado == 0):\n",
        "    label = label + \": Em pe proximo a um veiculo\"\n",
        "    color = [0, 215, 255]\n",
        "  elif(estado == 1):\n",
        "    label = label + \": Agachado(a) proximo a um veiculo\"\n",
        "    color = [0, 95, 255]\n",
        "  else:\n",
        "    label = label + \": Suspeito(a)\"\n",
        "    color = [0, 0, 255]\n",
        "\n",
        "  # Adiciona os frames de deteccao da pessoa no texto\n",
        "  label = label + \"(\" + str(frames_passados) + \"f)\"\n",
        "\n",
        "  # Chama o metodo de plot do esqueleto usando as cores definidas\n",
        "  plot_skeleton_kpts(frame, kpts, kpts_conf, color, orig_shape=None)\n",
        "\n",
        "  # Extrai os tons\n",
        "  r,g,b = color[:]\n",
        "\n",
        "  # Extrai as coordenadas da caixa\n",
        "  x1 = int(box[0].item())\n",
        "  y1 = int(box[1].item())\n",
        "  x2 = int(box[2].item())\n",
        "  y2 = int(box[3].item())\n",
        "\n",
        "  # Define espessura da linha\n",
        "  tl = round(0.002 * (frame.shape[0] + frame.shape[1]) / 2) + 1\n",
        "\n",
        "  # Define espessura da fonte\n",
        "  tf = max(tl - 1, 1)\n",
        "\n",
        "  # Extrai o tamanho do texto\n",
        "  t_size = cv2.getTextSize(label, 0, fontScale=tl / 3.7, thickness=tl)[0]\n",
        "\n",
        "  # Define nova coordenada para o retangulo do texto\n",
        "  c2 = x1 + t_size[0], y1 - t_size[1] - 3\n",
        "\n",
        "  # Extrai altura e largura do texto para ser proporcional com o tamanho\n",
        "  (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
        "\n",
        "  # Plota o retangulo da caixa\n",
        "  cv2.rectangle(frame, (x1, y1), (x2, y2), (r, g, b), 2)\n",
        "\n",
        "  # Plota o retangulo do texto\n",
        "  cv2.rectangle(frame, (x1, y1), c2, (r, g, b), -1, cv2.LINE_AA)\n",
        "\n",
        "  # Plota o texto\n",
        "  cv2.putText(frame, label, (x1, y1 - 2), 0, tl / 3.7, [255, 255, 255], 2, cv2.LINE_AA)"
      ],
      "metadata": {
        "id": "ETdoPpqEddvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Método que efetua detecção de comportamentos pré-definidos como suspeitos**\n"
      ],
      "metadata": {
        "id": "udzGefaCIgmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_detection(video_path, video, out_path='/content/'):\n",
        "\n",
        "  # Obtem o caminho do video\n",
        "  colab_video_path = video_path + video\n",
        "\n",
        "  # Abre o video\n",
        "  cap = cv2.VideoCapture(colab_video_path)\n",
        "\n",
        "  # Finaliza se o video for vazio\n",
        "  if cap is None:\n",
        "    return\n",
        "\n",
        "  # Define nome do video de saida\n",
        "  if video.endswith('.mp4'):\n",
        "    filename = out_path + (video.replace('.mp4', '') +'_output.mp4')\n",
        "  elif video.endswith('.avi'):\n",
        "    filename = out_path + (video.replace('.avi', '') +'_output.avi')\n",
        "\n",
        "  # Define VideoWriter para salvar video de saida\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "  out = cv2.VideoWriter(video, fourcc, (30.0 if fps is None else fps), (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "  # Obtem o framerate para contabilizar o tempo\n",
        "  fps = None\n",
        "  if cap is not None:\n",
        "      fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  else:\n",
        "      fps = 30\n",
        "\n",
        "  # Dicionários para armazenar o histórico de track\n",
        "  track_history_reference = defaultdict(lambda: 30)\n",
        "  track_history_time = defaultdict(lambda: 0)\n",
        "\n",
        "  # Percorre os frames do video\n",
        "  while cap.isOpened():\n",
        "      # Faz leitura do frame atual\n",
        "      success, frame = cap.read()\n",
        "\n",
        "      # Verifica se a leitura foi um sucesso e o frame nao eh nulo\n",
        "      if success and frame is not None:\n",
        "          # Executa a inferencia do YOLOv8 de pessoas, motos e carros sem tracking\n",
        "          results = model(frame, classes=[0,2,3], conf=0.7, iou=0.7)\n",
        "\n",
        "          # Array para testar interseccao\n",
        "          persons = []\n",
        "          vehicles = []\n",
        "\n",
        "          # Verifica se a caixa eh de uma pessoa ou veiculo e guarda no array correspondente\n",
        "          for r in results: # 1 resultado por entrada\n",
        "              boxes = r.boxes\n",
        "              for box in boxes:\n",
        "                  b = box.xyxy[0].numpy()  # get box coordinates in (top, left, bottom, right) format (transformando em array)\n",
        "                  c = int(box.cls)\n",
        "                  if (c == 0):\n",
        "                    persons.append(b)\n",
        "                  elif (c == 2 or c == 3):\n",
        "                    vehicles.append(b)\n",
        "\n",
        "          # Testa ocorreu interseccao entre pessoa e veiculo para rodar o outro modelo\n",
        "          intersection = False\n",
        "          if persons and vehicles:\n",
        "            for aux, person_box in enumerate(persons):\n",
        "                for vehicle_box in vehicles:\n",
        "                    if bbox_iou_vehicle(vehicle_box, person_box) > 0: # Detecta a intersecao\n",
        "                        intersection = True\n",
        "                        persons.pop(aux) # Retira a pessoa a ser analisada da lista de pessoas\n",
        "                        break\n",
        "\n",
        "          # Se houve alguma interseccao, roda o modelo de pontos-chave\n",
        "          pessoas_atualizadas = [] # Pessoas detectadas no frame\n",
        "          if(intersection):\n",
        "            # Executa a inferencia do YOLOv8 de pontos-chave com tracking\n",
        "            results = model_kpts.track(frame, persist=True, conf=0.3, iou=0.7)\n",
        "\n",
        "            # Obtem caixas das pessoas com pontos-chave\n",
        "            boxes = results[0].boxes.xyxy.cpu()\n",
        "\n",
        "            # Obtem IDs\n",
        "            track_ids = None\n",
        "            if results[0].boxes.id is not None:\n",
        "              track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "\n",
        "            # Obtem coordenadas dos pontos-chave\n",
        "            keypoints = results[0].keypoints.xy.numpy(); # Limita a informação para xyxy\n",
        "\n",
        "            # Obtem confianca dos pontos-chave\n",
        "            keypoints_conf = None\n",
        "            if results[0].keypoints.conf is not None:\n",
        "              keypoints_conf = results[0].keypoints.conf.numpy(); # Conf de cada keypoint\n",
        "\n",
        "            # Verifica se todas as pessoas detectadas tem ids\n",
        "            if track_ids and keypoints_conf is not None and (len(track_ids) == len(keypoints_conf)):\n",
        "              # Percorre cada pessoa detectada com o modelo de pontos-chave\n",
        "              for box, track_id, kpts, kpts_conf in zip(boxes, track_ids, keypoints, keypoints_conf):\n",
        "                # Adiciona 1 frame no historico da pessoa com o ID correspondente\n",
        "                track_history_time[track_id] += 1\n",
        "\n",
        "                # Testa se pessoa esta agachada e define o estado baseado no tempo (frames)\n",
        "                estado = None\n",
        "                squat = is_squat(kpts)\n",
        "                if not squat and track_history_time[track_id] < (fps*6):\n",
        "                  estado = 0\n",
        "                elif squat and track_history_time[track_id] < (fps*3):\n",
        "                  estado = 1\n",
        "                else:\n",
        "                  estado = 2\n",
        "                  suspeito = True\n",
        "\n",
        "                # Chama o metodo de plot\n",
        "                plot_keypoints_detection(frame, kpts, kpts_conf, box, estado, track_id, track_history_time[track_id])\n",
        "\n",
        "                # Atualiza a lista de pessoas atualizadas\n",
        "                pessoas_atualizadas.append(track_id)\n",
        "\n",
        "          # Percorre cada ID no dic de pessoas rastreadas e diminui em 1 frame a contagem limite de referencia caso nao esteja no frame\n",
        "          for chave in list(track_history_reference.keys()):\n",
        "              if chave not in pessoas_atualizadas:\n",
        "                  track_history_reference[chave] -= 1\n",
        "                  if track_history_reference[chave] <= 0: # Se a contagem chegar a 0, deleta a referência dessa pessoa\n",
        "                    track_history_reference.pop(chave)\n",
        "                    track_history_time.pop(chave)\n",
        "\n",
        "          # Plota pessoas sem interseccao e todos os veiculos\n",
        "          if persons:\n",
        "            plot_detections(frame, persons, [0, 255, 0], 'pessoa', 3)\n",
        "          if vehicles:\n",
        "            plot_detections(frame, vehicles, [140, 45, 45], 'veiculo', 3)\n",
        "\n",
        "          # Escreve o frame no video de saida\n",
        "          frame = cv2.resize(frame, (int(cap.get(3)), int(cap.get(4))))\n",
        "          out.write(frame)\n",
        "\n",
        "          # Interrompe o loop se a tecla 'q' for pressionada\n",
        "          if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "              break\n",
        "      else:\n",
        "          # Interrompe o loop se o final do video for alcançado\n",
        "          break\n",
        "\n",
        "  # Libera o objeto de captura de video e fecha a janela de exibição\n",
        "  cap.release()\n",
        "  out.release()\n",
        "  cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Vt1ZW0GXKQIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Execução da detecção de comportamentos pré-definidos como suspeitos**\n",
        "#### Para definir o caminho do diretório ou vídeo, basta alterar o caminho na variável *path*."
      ],
      "metadata": {
        "id": "Vz2RHfWuHJP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho do video (mude aqui)\n",
        "path = '/content/drive/MyDrive/Rodar/SBSI/positivo/'\n",
        "\n",
        "# Inicia contador\n",
        "inicio_tempo = time.time()\n",
        "\n",
        "# Verifica se eh um diretorio\n",
        "if isdir(path):\n",
        "  # Obtem a lista de videos na pasta (caso seja uma pasta)\n",
        "  videos = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "  # Percorre os videos\n",
        "  for video in videos:\n",
        "    # Verifica se o video esta no formato correto e nao eh um video processado\n",
        "    if video.endswith('.mp4') or video.endswith('.avi') and not video.endswith('_output.mp4'):\n",
        "      print(\"Rodando o video: \" + str(video))\n",
        "      # Executa deteccao\n",
        "      run_detection(path, video)\n",
        "elif isfile(path):\n",
        "  # Executa deteccao\n",
        "  run_detection(path)\n",
        "\n",
        "# Finaliza contador\n",
        "fim_tempo = time.time()\n",
        "\n",
        "print('Tempo médio de execução: ' + str((fim_tempo-inicio_tempo)/len(videos)) + 's')"
      ],
      "metadata": {
        "id": "j0lrPIWqI5fj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kjrLfdBDkMIu",
        "IygowPq5Akss",
        "vQSDblCmkTuN",
        "HdGcWFJiBNBm",
        "QahkjqKPa4Ca",
        "Lv4xMaUd0vpo"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}